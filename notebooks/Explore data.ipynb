{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data\n",
    "To see how we can use our data, we do some investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rinze\\.conda\\envs\\matrix\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yellowbrick.regressor import ResidualsPlot, PredictionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle file\n",
    "df = pd.read_pickle(\"../data/intermediate.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in df.columns if col.startswith(\"vve\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp solution\n",
    "df.rename(columns={\"rf_plat dak\": \"rf_plat_dak\", \n",
    "                   \"address_x\": \"address\"}, \n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a subset without neighborhoods for correlation check\n",
    "subset = df[[col for col in df.columns if not col.startswith(\"ne\")]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation check\n",
    "Initially we want to know what factors have a big influence on the asking price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Produce a heatmap \n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "sns.heatmap(subset.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be high correlation between the various VVE columns, so we decide to drop all but 1.\n",
    "\n",
    "The same applies to for 2 roof types and forms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "vve = [col \n",
    "       for col in df.columns \n",
    "       if col.startswith(\"vve\") \n",
    "       and col not in [\"vve_contribution\", \"vve_maintenance\"]]\n",
    "others = [\"rt_pannen\", \"rf_plat_dak\", \"address\", \"price_m2\"]\n",
    "\n",
    "a = df.drop(columns=vve + others)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason the model doesn't work when we remove all these columns, so only address and price_m2 are removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation viewed related to asking price\n",
    "corr_series = df.corr()[[\"asking_price\"]].sort_values(by=\"asking_price\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(corr_series[1:20], \n",
    "                      vmin=-1, \n",
    "                      vmax=1, \n",
    "                      annot=True, \n",
    "                      cmap='BrBG')\n",
    "heatmap.set_title(\"Correlation with asking price\", \n",
    "                  fontdict={'fontsize':18}, \n",
    "                  pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select column names of factors with more than 2 values\n",
    "num_cols = [col for col in df.columns \n",
    "            if df[col].nunique() > 2 \n",
    "            and df[col].dtype in [\"int64\", \"float64\"] \n",
    "            and col != \"asking_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"days_online\"].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit scaler model and apply to dataframe\n",
    "std = StandardScaler()\n",
    "scaled_fit = std.fit(df[num_cols])\n",
    "df[num_cols] = pd.DataFrame(scaled_fit.transform(df[num_cols]), columns=num_cols)\n",
    "df[\"days_online\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "X = df[[col for col in df.columns if col != \"asking_price\"]]\n",
    "y = df[\"asking_price\"]\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "Now we train a model to check for linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the class\n",
    "lin_model = linear_model.LinearRegression()\n",
    "# Create the model\n",
    "lin_model.fit(X_train, y_train)\n",
    "score = lin_model.score(X_train, y_train)\n",
    "print(f\"R2: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial score (0.70) is not very high. This could have various reasons. Most obvious is the way we selected our features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(plot, model, train, test):\n",
    "    visualizer = plot(model)\n",
    "    visualizer.fit(*train)\n",
    "    visualizer.score(*test)\n",
    "    visualizer.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(2, 1, figsize=(16,10))\n",
    "for i, plot in enumerate([ResidualsPlot, PredictionError]):\n",
    "    visualize_model(plot, lin_model, (X_train, y_train), (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "The points are not randomly dispersed around the horizontal axis,  which means that a linear regression model is probably not appropriate for the data and we should use a non-linear model. The R<sup>2</sup> for the training set is very good, however the R<sup>2</sup> for the test set is average, which also shows in the fact that the train data (green) is normally distributed around 0, but not the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Externalize in full func\n",
    "To be able to run the full thing in one go, we save the whole thing in a external script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rinze\\.conda\\envs\\matrix\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.import_module(\"modelling\")\n",
    "import modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = modelling.DataFrameModel(\"intermediate.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----LR-----\n",
      "\n",
      "\n",
      "Model achieved an mean absolute error of 118270.104.\n",
      "R2 score is 0.608\n",
      "\n",
      "-----DT-----\n",
      "\n",
      "\n",
      "Model achieved an mean absolute error of 115000.000.\n",
      "R2 score is 0.339\n"
     ]
    }
   ],
   "source": [
    "models = [\"LR\", \"DT\", \"RF\"]\n",
    "for model in models:\n",
    "    mdl.evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
